from Benchmark import INES
import traceback
import logging
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor
import os
import pandas as pd
import sys

# logging.basicConfig(
#     filename="simulation_errors.log",  # Save errors in a .log file
#     level=logging.ERROR,
#     format="%(asctime)s - %(levelname)s - %(message)s"
# )


def run_simulation(
    nodes,
    node_event_ratio,
    num_eventtypes,
    eventskew,
    max_parents,
    query_size,
    query_length,
    run,
):
    log_file_name = f"simulation_{os.getpid()}.log"  # Unique log per process
    sys.stdout = open(log_file_name, "a")  # Redirect stdout

    run_timestamp = datetime.now().strftime("%d-%m-%Y %H:%M:%S")
    log_separator = (
        f"\n{'=' * 40}\nSimulation Run #{run} - {run_timestamp}\n{'=' * 40}\n"
    )

    print(f"\n==== Simulation Run {run} Started ====\n")
    sys.stdout.flush()  # Force immediate write
    try:
        print(f"\n==== Initaiting Run {run} Started ====\n")
        simulation = INES(
            nodes,
            node_event_ratio,
            num_eventtypes,
            eventskew,
            max_parents,
            query_size,
            query_length,
        )
        sys.stdout.flush()
        return pd.DataFrame(
            [[simulation.function_times.get(key, None) for key in simulation.schema]],
            columns=simulation.schema,
        )  # Convert results to DataFrame

    except Exception as e:
        error_message = f"‚ùå Exception: {str(e)}\n{traceback.format_exc()}"
        log_file_name = f"simulation_errors_{os.getpid()}.log"
        print(error_message)
        sys.stdout.flush()
        # Log with a separator for each simulation run
        with open(log_file_name, "a") as log_file:
            log_file.write(log_separator)
            log_file.write(error_message)

        print(f"Error in simulation run {run} logged.")

        return None


def start_simulation(
    nodes,
    node_event_ratio,
    num_eventtypes,
    eventskew,
    max_parents,
    query_size,
    query_length,
    runs,
):
    """Runs multiple simulations in parallel."""
    file_name = f"INES-Benchmark" + datetime.now().strftime("%d%m%Y%H%M%S") + ".csv"
    result = run_simulation(
        nodes,
        node_event_ratio,
        num_eventtypes,
        eventskew,
        max_parents,
        query_size,
        query_length,
        0,
    )
    print(result)
    all_results = []

    with ProcessPoolExecutor(max_workers=4) as executor:  # Adjust max_workers as needed
        futures = [
            executor.submit(
                run_simulation,
                nodes,
                node_event_ratio,
                num_eventtypes,
                eventskew,
                max_parents,
                query_size,
                query_length,
                run,
            )
            for run in range(runs)
        ]

        for future in futures:
            print(f"üîÑ Checking result for run {future}")
            sys.stdout.flush()  # Ensure logs are visible

            try:
                result = future.result(
                    timeout=300
                )  # Set timeout to avoid infinite wait
                if result is not None:
                    all_results.append(result)
            except Exception as e:
                print(f"‚ö†Ô∏è Error in process: {e}")
            except TimeoutError:
                print(f"‚è≥ Timeout! Process took too long.")

    # Combine all DataFrames and write to CSV
    if all_results:
        all_results = [
            result for result in all_results if result is not None
        ]  # Remove failed runs
        final_df = pd.concat(all_results, ignore_index=True)
        final_df.to_csv(f"./res/{file_name}", index=False)
        print(f"Results saved to: {file_name}")


if __name__ == "__main__":
    # start_simulation(12, 0.5, 6, 0.3, 10, 3, 5, 4)
    file_name = f"INES-benchmark_" + datetime.now().strftime("%d%m%Y%H%M%S") + ".csv"
    all_results = []
    for i in range(3):
        # parallel laufen lassen
        result = run_simulation(50, 0.5, 6, 0.3, 10, 3, 5, i)
        all_results.append(result)

        if all_results:
            final_df = pd.concat(all_results, ignore_index=True)
            final_df.to_csv(f"./res/{file_name}", index=False)
            print(f"‚úÖ Results saved to: ./res/{file_name}")
        else:
            print("‚ùå No valid results found.")
