\chapter{Kraken\label{cha:kraken_framework}}

    This chapter details \emph{Kraken}, our joint optimization framework. We begin by outlining the framework's architecture and the foundational assumptions that define its scope in Section~\ref{sec:architecture_and_assumptions}. We then formalize the joint optimization task as a state-space search problem, defining the states, transitions, and search objectives in Section~\ref{sec:state_space_formulation}. A detailed discussion of our unified cost evaluation engine follows in Section~\ref{sec:unified_cost_framework}, which constitutes our primary contribution. We conclude by presenting the decoupled search strategies that navigate this complex solution space in Section~\ref{sec:search_strategies}.

\section{Framework Architecture and Assumptions}\label{sec:architecture_and_assumptions}

    This chapter presents Kraken, our joint optimization framework that addresses the first two research questions established in Chapter~\ref{cha:problem_statement}. We tackle \textbf{RQ1 (Cost Function Integration)} through our novel Unified Cost Evaluation Framework (C1), which integrates INEv placement costs with PrePP communication costs into a single optimization model. We address \textbf{RQ2 (State-Space Formulation and Search)} through our Decoupled Search Layer (C2), which formalizes the joint problem as a state-space search and implements pluggable heuristic strategies to navigate the exponential solution space efficiently. Together, these two components enable Kraken to discover superior solutions that sequential optimization approaches systematically overlook.

    Figure~\ref{fig:kraken_architecture} illustrates Kraken's architecture as a top-to-bottom pipeline that transforms static problem inputs into an optimal decentralized evaluation plan. The framework receives four static inputs \circlearound{1} defined in our problem formulation (Section~\ref{sec:problem_formulation}): the network topology $\Gamma$, the query workload $Q$, the event source function $\phi$, and the set of cloud sink nodes $N_c$. We assume these inputs are known \emph{a priori} and remain static throughout the optimization process, enabling deterministic cost and latency calculation during search. This static assumption, discussed further in Section~\ref{sec:limitations}, deliberately excludes dynamic network conditions and workload fluctuations to focus on the core joint optimization challenge.

        \begin{figure}[h]
        \centering
        \makebox[\linewidth][c]{%
          \includegraphics[width=0.91\linewidth]{img/chapter4/kraken_architecture_revised.pdf}
        }
        \caption{Kraken Architecture}
        \label{fig:kraken_architecture}
        \end{figure}

    The optimization process begins with a preprocessing stage that prepares the workload for joint optimization. In step \circlearound{2}, we invoke the INEv \emph{split} function (Section~\ref{sec:inev}), which decomposes the query workload $Q$ into a valid combination $C = (P, \delta)$ of projections $P$ and their dependencies $\delta$. Crucially, this decomposition uses an all-push cost model—a design decision we justify in Section~\ref{sec:correctness} based on feasibility guarantees and computational tractability. Step \circlearound{3} topologically sorts this combination to produce a \emph{processing order} $\mathcal{O}^P_Q$ (Definition~\ref{def:processing_order}). This ordering ensures that when we consider placing any projection $p$, all of its required inputs have already been placed and their locations are known. This ordering constraint fundamentally structures our state-space search, as detailed in Section~\ref{sec:state_space_formulation}.

    Kraken's optimization engine consists of two tightly integrated but architecturally decoupled layers. The \emph{Orchestration Layer (C1)} implements our domain-specific cost evaluation logic, directly addressing \textbf{RQ1} by unifying INEv placement costs with PrePP communication costs. The \emph{Search Layer (C2)} manages the exploration strategy, addressing \textbf{RQ2} by navigating the state-space efficiently using pluggable heuristic algorithms. This separation enables us to reason about cost integration and search strategies independently while maintaining their functional coupling through well-defined interfaces.

    The Orchestration Layer encapsulates our primary contribution: the integration of placement and communication cost functions into a unified evaluation model. Research Question 1 asks how we can \emph{effectively integrate} cost functions from INEv (operator placement) and PrePP (push-pull communication) into a framework that \emph{simultaneously determines} optimal decisions. Our answer manifests in C1's design, which treats each placement decision as inseparable from its communication strategy.

    The core mechanism is \emph{dual plan evaluation}. For each candidate (projection $p$, node $n$) pair that the search layer explores, step \circlearound{5} invokes our \texttt{calculate\_costs} function (detailed in Section~\ref{sec:unified_cost_framework}). Rather than committing to a single communication approach, this function generates two competing strategies in parallel \circlearound{6}: an all-push baseline plan $\hat{p}_{\text{push}}$ and an optimized push-pull plan $\hat{p}_{\text{PrePP}}$ computed by the PrePP algorithm. Both plans are evaluated using our extended PrePP cost model, which replaces PrePP's uniform network assumption with topology-specific distances derived from $dist$ (see Definition~\ref{def:network_distance}).

    However, raw cost calculation alone is insufficient for hierarchical fog-cloud environments. Steps \circlearound{7} and \circlearound{8} apply two critical state-aware adjustments that account for the cumulative effects of previous placement decisions. The \emph{Local Event Correction} (C1.1, Section~\ref{sec:local_event_correction}) exploits event reuse opportunities: when projections co-locate at a node, intermediate results produced by earlier-placed projections become locally available to later projections, eliminating redundant transmission costs. The \emph{Sink Cost Adjustment} (C1.2, Section~\ref{sec:sink_cost_adjustment}) accounts for result delivery to cloud sinks $N_c$, a requirement absent from INEv's original sink-at-evaluation-node assumption but essential for realistic fog-cloud deployment where fog nodes evaluate queries but clouds consume results.

    After applying these corrections, step \circlearound{9} scores each candidate using our \emph{Multi-Objective Cost Function} (C1.3, Section~\ref{sec:multi_objective_state_scoring}), which normalizes heterogeneous transmission cost and latency metrics into a single comparable score. These scored candidates flow into the candidate pool \circlearound{10}, ready for the search layer to select from. This entire C1 pipeline—from dual evaluation through corrections to multi-objective scoring—directly answers RQ1 by providing a unified model where placement and communication are optimized jointly rather than sequentially.

    The Search Layer addresses Research Question 2: how can we formalize this joint problem as a state-space search and efficiently navigate the resulting NP-hard solution space? Our answer has two parts: a rigorous formalization (Section~\ref{sec:state_space_formulation}) and a pluggable architecture that decouples search strategy from domain logic.

    The search proceeds iteratively through the processing order $\mathcal{O}^P_Q$. At each step, the search layer selects a current state (or set of states, depending on strategy) and invokes the \texttt{expand} function \circlearound{4} (Algorithm~\ref{alg:expand}) to generate successor states. This expansion function bridges the two layers: it calls C1's cost evaluation for each candidate, receives back the scored results from the candidate pool \circlearound{10}, and returns all valid successors to the search strategy. The search strategy \circlearound{11} then decides which successor(s) to explore next based on their objective scores, without needing any domain-specific knowledge about operator placement or push-pull communication.

    We implement two concrete strategies (Section~\ref{sec:search_strategies}): \emph{Greedy Search}, which maintains a single current state and always selects the locally best successor, and \emph{Beam-$k$ Search}, which maintains $k$ parallel states to explore more of the solution space at $k$-times computational cost. This pluggable architecture demonstrates that the joint optimization problem, despite its domain complexity, can be abstracted to a generic state-space search where the only domain-specific operations are state expansion (which invokes C1) and state scoring (computed by C1). Section~\ref{sec:extensibility} discusses how this architecture enables future integration of more sophisticated search algorithms like $A^*$ or branch-and-bound without modifying the cost evaluation logic.

    When the search reaches a goal state (all projections placed), it returns the complete optimal INEv graph $I^* = (V, E_{\text{INEv}})$ \circlearound{12}. This graph minimizes the total transmission cost $C(I^*) = \sum_{v \in V} c(v_{\text{steps}})$ subject to query correctness, valid PrePP plans, and the latency constraint $L(I^*) \leq \Lambda_{\text{max}}$. Each vertex $v \in V$ specifies not just a projection $v_{\text{proj}}$ and placement $v_{\text{node}}$, but also the specific PrePP acquisition steps $v_{\text{steps}}$ selected during joint optimization—the complete atomic decision unit that enables Kraken to discover solutions sequential approaches cannot find.

\section{State Space Formulation}\label{sec:state_space_formulation}

    We formalize the joint optimization problem as a state-space search. This formulation allows us to represent the complex, multi-dimensional solution space in a structured manner. We treat the process of building a complete evaluation plan as a sequence of decisions. Each partial plan represents a \emph{state} and the act of adding a new placed projection creates a \emph{transition} to a new state. This approach requires us to formally define four key components:
    \begin{itemize}
        \item \textbf{Kraken Vertex}: The fundamental building block of a solution (Section~\ref{sec:kraken_vertex}).
        \item \textbf{The State}: Represents a partial or complete solution (Section~\ref{sec:state_representation}).
        \item \textbf{The Solution Space}: The set of all possible states (Section~\ref{sec:state_representation}.
        \item \textbf{Search Problem}: The formal definition of the problem itself (Section~\ref{sec:search_problem_def}).
    \end{itemize}

    This section defines these components in order, building from the atomic vertex to the complete problem definition.

    \subsection{The Kraken Vertex}\label{sec:kraken_vertex}

        The core of our joint representation is the \emph{Kraken vertex}. We design this structure to represent a complete, atomic decentralization decision. A Kraken vertex $v$ encapsulates the three components of this decision: the projection to evaluate, the node that evaluates it, and the sequence of steps to acquire the necessary data. This approach resolves the redundancy noted in the \ac{PrePP} plan definition (Definition~\ref{def:prepp_plan}), which already contains the evaluation node. We therefore define the vertex by storing the projection, the node, and only the \emph{steps} component of the \ac{PrePP} plan.

        \begin{definition}[Kraken Vertex]\label{def:kraken_vertex}
        A \emph{Kraken vertex} $v$ is a tuple $v = (v_{\text{proj}}, v_{\text{node}}, v_{\text{steps}})$ where:
        \begin{itemize}
            \item $v_{\text{proj}} \in \Pi_Q$: The projection being placed (Definition~\ref{def:projection}).
            \item $v_{\text{node}} \in N$: The network node where $v_{\text{proj}}$ evaluates (Definition~\ref{def:network_topology}).
            \item $v_{\text{steps}}$: The sequence of acquisition steps $\langle a_1, \ldots, a_n \rangle$ (Definition~\ref{def:acquisition_step}) that $v_{\text{node}}$ executes to acquire the inputs for $v_{\text{proj}}$.
        \end{itemize}
        \end{definition}

        This structure fundamentally extends the original \ac{INEv} vertex model (Section~\ref{sec:inev})\cite{akili_inev_2023}. The original \ac{INEv} vertex, $v = (v_{\text{proj}}, v_{\text{node}}, v_{\text{graph}})$, captures placement ($v_{\text{proj}}$, $v_{\text{node}}$) but models communication abstractly as a forwarding subgraph ($v_{\text{graph}}$). Our Kraken vertex replaces this subgraph with $v_{\text{steps}}$, the concrete acquisition sequence derived from the \ac{PrePP} framework (Section~\ref{sec:communication}). This substitution directly integrates the communication strategy (the \emph{how}) with the projection $v_{\text{proj}}$ (the \emph{what}) and its location $v_{\text{node}}$ (the \emph{where}).

        The Kraken vertex $v$ thus atomically represents a complete, self-contained decentralization decision: a specific placement \textbf{and} its explicit communication strategy. This atomic binding is the key mechanism that enables our optimization framework to evaluate the total cost of a combined placement-communication decision simultaneously. This directly addresses the core challenge of joint optimization by preventing the sequential, decoupled evaluations that lead to suboptimal solutions.

    \subsection{State Representation}\label{sec:state_representation}

        This enhanced vertex is the fundamental atom of a solution. A complete evaluation plan, or "state" in our search, is a collection of these vertices. We now formally define this state, which must track both the placement decisions made and their effect on event availability across the network.
        \begin{definition}[Solution Candidate]\label{def:solution_candidate}
            A search state, or \textbf{solution candidate}, represents a partial or complete \ac{INEv} graph. We define this state $s$ as a tuple $s = (\mathcal{V}_s, \mathcal{T}_s)$:

            \begin{itemize}
              \item $\mathcal{V}_s: P' \to V_{I_s}$ is the \textbf{placement map}. It maps a subset of placed projections $P' \subseteq P$ to their corresponding Kraken vertices $v \in V$.
              \item $\mathcal{T}_s: N \to 2^{\epsilon}$ is the \textbf{event availability map}. It maps each network node $n \in N$ to the set of event types $\epsilon_n \subseteq \epsilon$ currently available at that node. This map is critical for our local event correction (C1.1).
            \end{itemize}
        \end{definition}

        A single state represents one partial solution. The solution space defines the entire set of possible states our algorithm can explore, bounded by an empty plan and all possible complete plans.

        \begin{definition}[Solution Space]\label{def:solution_space}

            The \textbf{solution space} $\mathcal{S}$ consists of all possible valid solution candidates. This space is bounded by:

            \begin{itemize}
              \item The \textbf{initial state} $s_0 = (\emptyset, \mathcal{T}_0)$, where no projections are placed ($\mathcal{V}_{s_0}$ is empty) and event availability $\mathcal{T}_0$ is populated only by primitive events at their source nodes (per $\phi$).
              \item A \textbf{goal state} $s^* \in \mathcal{S}_G$, which is any state $s$ where all projections have been placed, satisfying $\text{dom}(\mathcal{V}_s) = P$.
            \end{itemize}

        \end{definition}

    \subsection{Search Problem Definition}\label{sec:search_problem_def}

        Defining the states and the space is insufficient; we must formalize the problem of finding the optimal path through this space. This requires defining the inputs that guide the search, specifically the order in which we place projections and a method for measuring network distance.

        \begin{definition}[Processing Order]\label{def:processing_order}

            Let $C_Q = (P, \delta)$ be a valid combination for evaluating workload $Q$.
            A \textbf{processing order}

            $$\mathcal{O}^P_Q = \langle p_1, \ldots, p_n \rangle$$

            is a topologically sorted sequence of all projections $p \in P$.This ordering respects the precedence relation $\delta$, ensuring that every projection $p_i$ appears in the sequence only after all of its dependencies $\delta(p_i)$ have appeared. This guarantees that when our search algorithm considers placing $p_i$, all its required inputs are already available from previously placed projections.

        \end{definition}

        \begin{definition}[Network Distance Function]\label{def:network_distance}

            Given the network topology $\Gamma = (N, E, g)$ and a link cost function $d: E \to \mathbb{R}^+$ that assigns a cost to each communication link $e \in E$, we define the \emph{network distance function}:

            $$\text{dist}: N \times N \to \mathbb{R}^+ \cup \{\infty\}$$

            This function computes the minimum cumulative cost for the shortest path from node $n_i$ to node $n_j$ in the network graph. Formally, let $P(n_i, n_j)$ be the set of all possible paths from $n_i$ to $n_j$ in $\Gamma$. A path $p \in P(n_i, n_j)$ is a sequence of edges $p = \langle e_1, e_2, \ldots, e_k \rangle$.
            The distance is defined as the minimum path cost:

            $$\text{dist}(n_i, n_j) = \min_{p \in P(n_i, n_j)} \left( \sum_{e \in p} d(e) \right)$$

            If no path exists ($P(n_i, n_j) = \emptyset$), then $\text{dist}(n_i, n_j) = \infty$.

        \end{definition}

        With these components—the state space, the processing order, and the distance function—we can now formally define the complete placement problem that our search algorithm solves.

        \begin{definition}[Placement Problem]\label{def:placement_problem}

            We define a \textbf{placement problem} $\mathcal{P}$ as a tuple:

            $$\mathcal{P} = (\mathcal{S}, \mathcal{O}^P_Q, \Gamma, s_0, \mathcal{S}_G, \text{expand}, \Lambda_{\text{max}}, \alpha, \beta).$$

            This tuple integrates all components required for a guided search:

            \begin{itemize}
              \item $\mathcal{S}$, $s_0$, $\mathcal{S}_G$: The solution space, initial state, and goal states.
              \item $\mathcal{O}^P_Q$: The \textbf{processing order} that ensures we only place projections whose inputs are available.
              \item $\Gamma$: The network topology, used to compute the \textbf{network distance function} $\text{dist}(n_i, n_j)$.
              \item $\Lambda_{\text{max}}$: A maximum allowable end-to-end transmission latency.
              \item $\alpha, \beta$: Weights for the multi-objective cost function ($\alpha + \beta = 1$).
              \item $\text{expand}$: The state transition function (Algorithm~\ref{alg:expand}) that generates successor states.
            \end{itemize}

            The objective is to find a goal state $s^* \in \mathcal{S}_G$ that minimizes the weighted objective function (defined in Section~\ref{sec:multi_objective_state_scoring}) while satisfying the constraint $L_{s^*} \leq \Lambda_{\text{max}}$.
        \end{definition}

    \subsection{State Transition Function}

        The \texttt{expand} function (Algorithm~\ref{alg:expand}) generates all valid successor states from a non-goal state $s_i$. It selects the next unplaced projection $p$ based on the processing order $\mathcal{O}^P_Q$. For this projection, it identifies all valid candidate nodes $N_{\text{cand}} \subseteq N_f \cup N_c$.

        Crucially, it sorts these nodes  to optimize pruning ((see Line 4,$N_{\text{sorted}}$)). In particular, nodes where $p$'s dependencies are already available (from $\mathcal{T}_s$) are prioritized, followed by nodes in ascending order of network distance to event sources. This sorting ensures that if a node $n$ violates the latency constraint $\Lambda_{\text{max}}$, all subsequent nodes in the sorted list (which are farther away) will also violate it, allowing for aggressive pruning.

        For each candidate node $n$, the function invokes \texttt{calculate\_costs} (Algorithm~\ref{alg:calculate_costs}) to generate all valid communication strategies $R_{\text{strat}}$ (both all-push and optimized push-pull). It creates a new state $s_{\text{next}}$ for each strategy, calculates its critical path latency, and prunes it if $L_{\text{critical}} > \Lambda_{\text{max}}$. The function returns all surviving successor states, sorted by their objective score, ready for the search algorithm.

        \begin{algorithm}[h]
            \caption{State Expansion \texttt{expand}($s_i$)}
            \label{alg:expand}
            \SetAlgoLined
            \SetKwInOut{Parameter}{Parameters}
            \Parameter{
            Non-goal state $s_i \in \mathcal{S}$,\\
            Processing order $\mathcal{O}^P_Q$,\\
            Constraint $\Lambda_{\text{max}}$,\\
            Path set $\mathcal{P}$,\\
            Problem context $\mathcal{C}$
            }

            $k \gets |\mathcal{V}_{s_i}|$ \tcp*[r]{Number of placed projections}
            $p \gets p_{k+1}$ from $\mathcal{O}^P_Q$ \tcp*[r]{Next projection in order}

            $N_{\text{cand}} \gets \texttt{get\_possible\_nodes}(p, s_i)$ \tcp*[r]{$N_{\text{cand}} \subseteq N_f \cup N_c$}

            $N_{\text{sorted}} \gets \texttt{sort\_nodes}(N_{\text{cand}}, p, s_i.\mathcal{T}_s)$\;

            $S' \gets \emptyset$ \tcp*[r]{Successor states}

            \ForEach{$n \in N_{\text{sorted}}$}{
              $R_{\text{strat}} \gets \texttt{calculate\_costs}(p, n, s_i)$ \tcp*[r]{Algorithm~\ref{alg:calculate_costs}}
              \ForEach{$r \in R_{\text{strat}}$}{
                $s_{\text{next}} \gets \texttt{create\_next\_candidate}(s_i, p, n, r)$\;
                $L_{\text{critical}} \gets s_{\text{next}}.\texttt{get\_critical\_path\_latency}(\mathcal{P})$ \tcp*[r]{End-to-end $L^t_s$}
                \If{$L_{\text{critical}} \le \Lambda_{\text{max}}$}{
                  $S' \gets S' \cup \{s_{\text{next}}\}$ \tcp*[r]{Prune by latency constraint}
                }
              }
            }

            \KwRet{$\text{sort}(S', \text{ by } F(\cdot))$} \tcp*[r]{Equation~\ref{eq:objective_function}}
        \end{algorithm}

    \newpage

    \subsection{Example: From Vertex Generation to State Selection}\label{subsec:state_space_example}
        \begin{figure}[h]
            \centering
            \includegraphics[width=\linewidth]{img/chapter4/search_space_decoupling.pdf}
            \caption{Decoupling of INEv construction and search space.}
            \label{fig:search_space_decoupling}
        \end{figure}

        We demonstrate our state-space formulation using the smart factory scenario (Section~\ref{sec:motivating_example}), focusing on placing $p = \text{SEQ}(P,H)$. We start from the initial state $s_0$, where only source nodes are placed. The process, illustrated in Figure~\ref{fig:search_space_decoupling}, begins by selecting the projection $p$ for placement \circlearound{1}. The \texttt{expand} function (Algorithm~\ref{alg:expand}) then processes this projection \circlearound{2}. It identifies two candidate nodes, fog $n_1^f$ and cloud $n_0^c$, and evaluates two communication strategies for each: all-push ($\hat{p}_{\text{push}}$) and optimized PrePP ($\hat{p}_{\text{PrePP}}$), as modeled in Section~\ref{sec:communication}. This joint evaluation generates four Kraken vertices (Definition~\ref{def:kraken_vertex}) on the left: $v_1$ (fog, push), $v_2$ (fog, PrePP), $v_3$ (cloud, push), and $v_4$ (cloud, PrePP). These vertices correspond directly to four distinct successor states ($s_1$ through $s_4$) in the search space, shown on the right \circlearound{3}.

        The unified cost framework (Section~\ref{sec:unified_cost_framework}) then evaluates each successor state. For this example, we deploy a cost-greedy search (Section~\ref{sec:search_strategies}) that ignores latency, consistent with the cost calculation in our motivating example. The search algorithm compares the total transmission costs for each state: $C(s_1) = 3610$, $C(s_2) = 2010$, $C(s_3) = 3620$, and $C(s_4) = 420$. The greedy strategy selects state $s_4$ as the next state because it provides the minimum cost \circlearoundBlue{4}. This selection demonstrates how the search navigates the solution space by simultaneously comparing competing placement-communication pairs to satisfy the optimization objective.

        \begin{figure}[h]
            \centering
            \includegraphics[width=0.7\linewidth]{img/chapter4/state_visualization.pdf}
            \caption{Representation of the Final State $s_4$.}
            \label{fig:state_visualization}
        \end{figure}

        Figure~\ref{fig:state_visualization} details the selected state $s_4$. The INEv graph (left) shows the vertex $\text{SEQ}(P,H)$ placed at $n_0^c$ using the specific plan $\hat{p}_{\text{PrePP}} = (n_0^c, \langle (\emptyset, \{P\}), (\{P\}, \{H\})\rangle)$. This plan, derived using the PrePP model (Section~\ref{sec:communication}), pushes low-rate $P$ events first, then uses them to pull only the relevant high-rate $H$ events. The compact state representation (right) summarizes the cumulative metrics for this solution, calculated using our Unified Cost Evaluation Framework (Section~\ref{sec:unified_cost_framework}): a total transmission cost of $C = 420$ units (as calculated in Section~\ref{sec:foundational_transmission_cost_model}), a transmission latency of $L^t = 6$ hops (as calculated in Section~\ref{sec:latency_modelling}), and a processing latency of $L^p = 189$ events (as calculated in Section~\ref{sec:latency_modelling}). This example illustrates our core contribution: the Kraken Vertex (Definition~\ref{def:kraken_vertex}) embeds placement and communication into a single, atomic unit. This joint evaluation enables Kraken to discover the globally optimal 420-unit cloud solution, which sequential optimization (Section~\ref{sec:motivating_example}) discards, converging instead on the suboptimal 2010-unit fog solution.

\section{Unified Cost Evaluation Framework}\label{sec:unified_cost_framework}

    In the remainder, we detail our unified cost evaluation framework (C1), which provides the core logic for the \texttt{calculate\_costs} function used by our expansion process. When the \texttt{expand} function (Algorithm~\ref{alg:expand}) considers placing a projection $p$ on a node $n$, it invokes this framework to:
    \begin{itemize}
        \item Generate all valid communication strategies for the $(p, n)$ pair.
        \item Calculate the precise cost and latency metrics for each strategy.
        \item Apply topology-aware corrections essential for hierarchical networks.
    \end{itemize}

    The framework's primary mechanism is a \emph{Dual Plan Evaluation} process. Instead of committing to a single communication strategy, it generates \emph{two} potential plans for the new vertex $v = (p, n)$:
    \begin{itemize}
        \item An \emph{All-Push Plan} ($\hat{p}_{push}$): the baseline strategy of pushing all raw event data.
        \item An \emph{Optimized Push-Pull Plan} ($\hat{p}_{PrePP}$): the optimized strategy generated by the PrePP algorithm \cite{purtzel_predicate-based_2022}.
    \end{itemize}

    The \texttt{calculate\_costs} function computes the metrics for both plans independently, applies our state-aware corrections (detailed in Section~\ref{sec:local_event_correction} and in Section~\ref{sec:sink_cost_adjustment}), and returns this set of strategies $R_{strat}$ to the \texttt{expand} function. If the PrePP algorithm determines that all-push is optimal, both plans $\hat{p}_{push}$ and $\hat{p}_{PrePP}$ are identical and $R_{strat}$ will contain only one unique entry.

    The \texttt{expand} function then creates a new successor state $s_{next}$ for each unique strategy in $R_{strat}$. This approach allows the search algorithm to simultaneously explore placement decisions and communication strategies as distinct branches in the solution space.

    \begin{algorithm}[h]
        \caption{$\texttt{calculate\_costs}(p, n, s_i)$}
        \label{alg:calculate_costs}
        \SetAlgoLined
        \SetKwInOut{Parameter}{Parameters}
        \SetKwInOut{Output}{Output}
        \SetKwComment{Comment}{$\triangleright$\ }{}
        \Parameter{
            Projection $p$,\\
            Candidate node $n$,\\
            Current state $s_i$
        }
        \Output{
            $R_{strat}$ \tcp*[r]{A set of Kraken vertices}
        }
        \texttt{\\}
        $R_{strat} \gets \emptyset$\;
        $\hat{P} \gets \{\hat{p}_{\text{push}}, \hat{p}_{\text{PrePP}}\}$ \tcp*[r]{Get the two candidate plans for $(p, n)$}
        \texttt{\\}
        \ForEach{$\hat{p} \in \hat{P}$}{
            \texttt{\\}
            \tcp{1. Calculate Raw Cost}
            $c_{raw},\ell^t_{raw}  \gets raw\_costs $\tcp*[r]{Section~\ref{sec:foundational_transmission_cost_model} and ~\ref{sec:latency_modelling}}
            \texttt{\\}
            \tcp{2. Apply Local Event Correction (C1.1)}
            $c' \gets \max(0, c_{raw} - \Delta c)$ \tcp*[r]{Section~\ref{subsubsec:cost_correction}}
            $\ell^{t'} \gets \ell^t_{raw} - \Delta \ell^t$\tcp*[r]{Section~\ref{subsubsec:latency_correction}}
            \texttt{\\}
            \tcp{3. Apply Sink Cost Adjustment (C1.2)}
            $c^{\text{final}} \gets c' + c_{sink}$\tcp*[r]{Section~\ref{sec:sink_cost_adjustment}}
            $\ell^{\text{final}} \gets \ell^{t'} + \ell^t_{sink}$\tcp*[r]{Section~\ref{sec:sink_cost_adjustment}}
            \texttt{\\}
            \tcp{4. Store final metrics for this plan}
            $R_{strat} \gets R_{strat} \cup \{(\hat{p}, c^{\text{final}}, \ell^{\text{final}})\}$\;
        }
        \texttt{\\}
        \KwRet{$R_{strat}$}\;
    \end{algorithm}

    We first describe the foundational cost models used to evaluate a single plan (Section~\ref{sec:foundational_transmission_cost_model}) and its associated latencies (Section~\ref{sec:latency_modelling}). We then detail the state-aware adjustments: \emph{Local Event Correction (C1.1)} (Section~\ref{sec:local_event_correction}) and \emph{Sink Cost Adjustment (C1.2)} (Section~\ref{sec:sink_cost_adjustment}). Finally, we explain how these metrics are aggregated at the state level (Section~\ref{sec:state_level_aggregation}) and scored in our \emph{Multi-Objective Scoring Function (C1.3)} (Section~\ref{sec:multi_objective_state_scoring}).

    \subsection{Foundational Transmission Cost Model}\label{sec:foundational_transmission_cost_model}

        We evaluate both $\hat{p}_{push}$ and $\hat{p}_{PrePP}$ using an extend PrePP cost model (see Section~\ref{subsec:cost_model_prepp}). The original PrePP model assumes uniform network costs. Our model incorporates the network specific distance function, $dist(n_i,n_j)$, which returns the distance from node $n_i$ to $n_j$ based on the network topology $\Gamma$ (see Definition~\ref{def:network_distance}).

        The total cost of a plan $\hat{p}$ for vertex $v$ is the sum of its acquisition steps:
        \begin{equation}\label{eq:sum_of_acquisition_steps}
            c(\hat{p}) = \sum_{a_i \in \hat{p}_{steps}} c(a_i)
        \end{equation}

        The cost for a single acquisition step $a_i = (\Psi_i, \rho_i)$ at node $n$ is:
        \begin{equation}\label{eq:cost_of_acquisition_step}
            c(a_i) = C_{req}(a_i) + C_{res}(a_i)
        \end{equation}

        \subsubsection{Pull Request Cost ($C_{req}$)}

            This is the cost of sending filtering predicates (from streams in pull set $\Psi_i$) from $n$ to all source nodes $n_s \in \bigcup_{S \in \rho_i}\phi^{-1}(S)$ that produce on of the required streams $S \in \rho_i$.
            \begin{equation}\label{eq:cost_of_pull_request}
                C_{req}(a_i) = \sum_{S' \in \Psi_i} R(S') \sum_{n_s \in \bigcup_{S \in \rho_i}\phi^{-1}(S)} dist(n, n_s)
            \end{equation}

            If $\Psi_i = \emptyset$ (a push step), this cost is $0$.

        \subsubsection{Pull Response Cost ($C_{res}$)}

            This is the cost of transmitting the filtered event data back from the sources $n_s$ to the evaluation node $n$.
            \begin{equation}\label{eq:cost_of_pull_response}
                C_{res}(a_i) = \sum_{S \in \rho_i} \sum_{n_s \in \phi^-1(S)} (r(n_s, S) \cdot \sigma(S \cup \Psi_i) \cdot dist(n_s, n))
            \end{equation}

            Here, we use the local event rate $r(n_s, S)$ at each source and the specific $\text{dist}(n_s, n)$. If $\Psi_i = \emptyset$, the selectivity $\sigma(\{S\})$ becomes $1.0$, and this formula correctly computes the all-push cost for events in $\rho_i$.

        \subsubsection{Example: Smart Factory Transmission Cost.}

            We apply this model to our smart factory example (Figure~\ref{fig:smart_factory_example}), placing $p = \text{SEQ}(P, H)$ at the cloud $n_0^c$. The topology requires 2 hops for all events (e.g., $\text{dist}(n_6^s, n_0^c) = 2$). Rates are $r(n_6^s, P) = 10$, $r(n_4^s, H) = 900$, $r(n_5^s, H) = 900$. Selectivity $\sigma(\{P, H\}) = 0.1$.


            \paragraph{All-Push Plan.}

            $\hat{p}_{\text{push}} = (n_0^c, \langle (\emptyset, \{P, H\}) \rangle)$.
              \begin{itemize}
                \item Cost of P (response only): $r(n_6^s, P) \cdot \sigma(\{P\}) \cdot \text{dist}(n_6^s, n_0^c) = 10 \cdot 1.0 \cdot 2 = 20$.
                \item Cost of H (response only): $(900 \cdot 1.0 \cdot 2) + (900 \cdot 1.0 \cdot 2) = 3600$.
                \item \textbf{Total Cost:} $20 + 3600 = 3620$ units.
                \item \textbf{Total Latency:} $\max(\text{dist}(n_6^s, n_0^c), \text{dist}(n_4^s, n_0^c), \ldots) = 2$ hops. This matches the baseline calculation from Figure~\ref{fig:central_evaluation}.
              \end{itemize}

            \paragraph{Push-Pull Plan.}

            $\hat{p}_{\text{pull}} = (n_0^c, \langle a_1, a_2 \rangle)$ where $a_1 = (\emptyset, \{P\})$ and $a_2 = (\{P\}, \{H\})$.
              \begin{itemize}
                \item \textbf{Step $a_1$ (Push P):}
                  \begin{itemize}
                    \item $C_{\text{req}}(a_1) = 0$.
                    \item $C_{\text{res}}(a_1) = 10 \cdot 1.0 \cdot 2 = 20$ units.
                    \item $c(a_1) = 20$. $\ell^t(a_1) = 2$ hops.
                  \end{itemize}
                \item \textbf{Step $a_2$ (Pull H):}
                  \begin{itemize}
                    \item $C_{\text{req}}(a_2)$: Send $P$ (rate $R(P)=10$) to 2 H-sources:\\
                    $10 \cdot (\text{dist}(n_0^c, n_4^s) + \text{dist}(n_0^c, n_5^s)) = 10 \cdot (2 + 2) = 40$ units.
                    \item $C_{\text{res}}(a_2)$: Get filtered H (selectivity $0.1$) from 2 sources:\\
                    $(900 \cdot 0.1 \cdot 2) + (900 \cdot 0.1 \cdot 2) = 180 + 180 = 360$ units.
                    \item $c(a_2) = 40 + 360 = 400$. $\ell^t(a_2) = \max(2, 2) + \max(2, 2) = 4$ hops.
                  \end{itemize}
                \item \textbf{Total Cost:} $c(a_1) + c(a_2) = 20 + 400 = 420$ units.
              \end{itemize}

    \subsection{Latency Modeling}\label{sec:latency_modelling}

        A primary challenge in multi-objective optimization is combining metrics with different units. Our framework accounts for \emph{transmission latency} (measured in network hops) and \emph{processing latency} (measured in the saved events processed per window). These two metrics are dimensionally incompatible.

        \todo[inline]{Add a paragraph that this framework can be very simple extended to use transmission latency and processing latency as one if the metrics align by setting $\xi$ to 1.}

        We address this by separating the concerns. The optimization search (Section~\ref{sec:search_strategies}) is guided \emph{only} by \emph{transmission latency} ($L^t_s$) as this is the dominant factor in distributed \ac{CEP}. We model and aggregate \emph{processing latency} ($L^p_s$) separately for post-optimization analysis, allowing us to assess the computational feasibilitiy of a solution at each node.

        This seperation is formalized by adapting the INEv latency model, which defines a vertex's latency as:

        \begin{equation}\label{eq:latency_model}
            \ell_v = \xi \cdot \ell^p_v + \ell^t_v +\max_{u \in \delta(v)}l(u)
        \end{equation}

        Our framework effectively sets the processing latency factor $\xi = 0$ during optimization, exluding the processing latency from the latency evaluation.

        \subsubsection{Transmission Latency($\ell^t_v$)}

        The transmission latency for a single vertex plan $\ell^t_v$ is the critical path of its acquisition steps $\hat{p}_{steps} = \{a_1, \dots, a_i\}$

        \begin{equation}\label{eq:transmission_latency_acquisition_step}
            \ell^t(a_i) = \ell^t_{req}(a_i) + \ell^t_{res}(a_i)
        \end{equation}

        where :

        \begin{equation}\label{eq:transmission_latency_pull_request}
            \ell^t_{req}(a_i) = \begin{cases}
                \max_{n_s \in \phi(\rho_i)} dist(v_{node}, n_s) & \text{if pull}\\
                0 & \text{otherwise}
            \end{cases}
        \end{equation}

        and

        \begin{equation}\label{eq:transmission_latency_pull_response}
            \ell^t_{res}(a_i) = \max_{n_s \in \phi(\rho_i)} dist(n_s, v_{node})
        \end{equation}

        The latency of a plan $\hat{p}_{steps}$ can be defined as:

        \begin{equation}\label{eq:entire_plan_transmission_latency}
            \ell^t_v = \sum_{a_i \in \hat{p}_{steps}} \ell^t(a_i)
        \end{equation}

        \subsubsection{Example: Smart Factory Transmission Latency.}

            \todo[inline]{Explain transmission latency shortly be referencing the exmaple above textbf{Total Latency:} $\ell^t(a_1) + \ell^t(a_2) = 2 + 4 = 6$ hops. }

        \subsubsection{Processing Latency ($\ell^p_v$)}

            We model processing latency $\ell^p_v$ as proportional to the volume of input events a projection processes. The baseline $\ell^p_{push}$ is the projection's output rate $r^{out}(p)$ representing the load of an all-push plan. An optimized plan $\hat{p}_v$ reduces this load by an input ratio $ratio(\hat{p}_v) = \frac{Vol_{plan}(\hat{p_v})}{Vol_{push}(p)}$, where $Vol$ is the volume of input events. The final processing latency is $\ell^p_v= r^{out}(p) \cdot ratio(\hat{p}_v)$.

        \subsubsection{Example: Smart Factory Processing Latency.}

            In our smart factory exmaple, the baseline processing latency for evaluating $p = \text{SEQ}(P,H)$ at $n_0^f$ is $r^{out}(p) = 1800$.

            For our optmized PrePP-plan $\hat{p}_{PrePP}$ the ratio is equal to
            \[
            ratio(\hat{p}_v) = \frac{90 + 90 +10}{1810} = 0.105
            \]
            which brings our transmission latency to
            \[
            \ell^p_v = r^{out}(p) \cdot ratio(\hat{p}_v) = 1800 \cdot 0.105 = 189
            \]
            Due to push-pull communication we've managed to decrease our transmission cost by $5\times$, however our transmission latency has decreased roughly $10\times$. This is because the transmission cost was counting the $P$ events multiple times (for pushing and sending the pull request), whilst the transmission latency is not.

    \subsection{Local Event Correction(1.2)}\label{sec:local_event_correction}

        After calculating the raw metrics ($c_{raw}, \ell^t_{raw}$) for a plan $\hat{p}$, the framework applies corrections based on the current solution state $s$. The state $s$ maintains an event availability map $\mathcal{T}_s(n)$ for each node $n$. When we place a projection $p$ at node $n$, its output $\mathcal{E}(p)$ is added to $\mathcal{T}_s(n)$, becoming locally available for subsequent projections placed at $n$.

        For a new plan $\hat{p}$ at node $n$, we compute corrections for cost and latency based on the events $\rho_i$ in each acquisition step $a_i = (\Psi_i, \rho_i)$ that are already available in $\mathcal{T}_s(n)$.

        \subsubsection{Cost Correction.}\label{subsubsec:cost_correction}

            The cost correction is applied per step $a_i$. Let $\rho_{\text{local}} = \rho_i \cap \mathcal{T}_s(n)$ be the set of required event types that are already local.

            \begin{equation}\label{eq:local_adjust_cost}
                \Delta c(a_i) =
                \begin{cases}
                    c(a_i) & \text{if } \rho_i \subseteq \mathcal{T}s(n) \\
                    \sum_{S \in \rho_{\text{local}}} c_{\text{res}}(S, a_i) & \text{otherwise}
                \end{cases}
            \end{equation}

            Here, $c_{\text{res}}(S, a_i)$ is the specific response cost for only the logical stream $S$ within step $a_i$, defined as:

            \begin{equation}\label{eq:specific_reponse_cost_local_adj}
                c_{\text{res}}(S, a_i) = \sum_{n_s \in \phi^{-1}(S)} (r(n_s, S) \cdot \sigma(\{S\} \cup \Psi_i) \cdot \text{dist}(n_s, n))
            \end{equation}

            This logic is precise: if all events for a step $a_i$ are local, the entire cost of that step (both request $C_{req}$ and response $C_{res}$) is nullified. If only some events are local (the otherwise case), we still incur the full $C_{req}$ cost to pull the remote events, so we only subtract the $C_{res}$ for the local-only events. The final corrected vertex cost is $c_v' = \max(0, c_v - \sum_{a_i \in \hat{p}_{\text{steps}}} \Delta c(a_i))$.

        \subsubsection{Latency Correction}\label{subsubsec:latency_correction}

        Latency adjustments follow a more conservative logic. A step's latency $\ell^t(a_i)$ represents the time spent waiting for the slowest remote event to arrive. This duration is only reduced to zero if the entire step $a_i$ becomes local, as partial availability does not reduce the time spent waiting for the non-local events.

        Therefore, the total latency correction $\Delta \ell^t_v$ is the sum of latencies for all steps that are fully satisfied locally:

        \begin{equation}\label{eq:local_latency_adjust}
            \Delta \ell^t_v(\hat{p}, n, s) = \sum_{a_i \in \hat{p}_{\text{steps}} \text{ s.t. } \rho_i \subseteq \mathcal{T}_s(n)} \ell^t(a_i)
        \end{equation}

        The final corrected vertex latency is $\ell^{t'}_v = \ell^t_v - \Delta \ell^t_v$. This combined correction mechanism enables the search to discover and correctly exploit the benefits of co-locating projections.

    \subsection{Sink Cost Adjustment~(C1.2)}\label{sec:sink_cost_adjustment}

        After adjusting for locality, we perform a second adjustment to the ... INEv, which is critical for our hierarchical fog-cloud environment, where the evaluation of a final query (e.g., at a fog node) and consumption (at the cloud) may occure at different locations.

        The transmission costs need to account for delivering the final query results to the designated cloud sinks $N_c$. This adjustment is applied to the intermediate metrics (e.g. $c_v'$) of \emph{both} plans, i.e., ... .

        In contrast, \ac{INEv} optimizes the sink placement so that the evaluation node is the final destination~\cite{akili_inev_2023, akili_muse_2021, purtzel_predicate-based_2022}. Consequently, INEv does not check the output rate of the root projections which leads to fan outs if such a root projections $p \in Q$ is placed at a non-sink node $n \notin N_c$. The sink cost is the cost to transmit the final result of the root projection, i.e., the rate $r^{out}(p)$, from $n$ to all sinks:

        \begin{equation}\label{eq:sink_cost}
            c_{sink}(p, n) =
            \begin{cases}
                r^{out}(p) \cdot \sum_{n_c \in N_c} dist(n, n_c) & \text{if } p \in Q \wedge n \notin N_c\\

                0 &\text{otherwise}
          \end{cases}
        \end{equation}

        The corresponding sink latency is the time to reach the farthest sink:
        \begin{equation}\label{eq:sink_latency}
        \ell_{\text{sink}}(p, n) = \begin{cases}
        \max_{n_c \in N_c} \text{dist}(n, n_c) & \text{if } p \in Q \wedge n \notin N_c \\
        0 & \text{otherwise}
        \end{cases}
        \end{equation}

        The final vertex cost $c_v^{\text{final}} = c_v' + c_{\text{sink}}$ and latency $\ell_v^{\text{final}} = \ell_v' + \ell_{\text{sink}}$ are the values that will be used to create the new solution state $s$.

    \subsection{State-Level Metric Aggregation}\label{sec:state_level_aggregation}

        When a new vertex $v$ (with its selected plan, e.g., $\hat{p}_{\text{push}}$) is added to a base state $s_{\text{base}}$, it produces a new derived state $s_{\text{next}}$. The aggregate metrics for $s_{\text{next}}$ are computed incrementally based on those of $s_{\text{base}}$ as follows:

        \begin{itemize}
            \item \textbf{Total Transmission Cost} ($C_s$):
            The overall transmission cost accumulates additively with each newly placed vertex:
            \begin{equation}\label{eq:state_cost_aggregation}
                C(s_{\text{next}}) = C(s_{\text{base}}) + c_v^{\text{final}}
            \end{equation}

            \item \textbf{Total Processing Latency} ($L^p_s$):
            Processing latency is similarly aggregated across the placed vertices:
            \begin{equation}\label{eq:state_processing_latency}
                L^p(s_{\text{next}}) = L^p(s_{\text{base}}) + \ell^p_v
            \end{equation}

            \item \textbf{End-to-End Transmission Latency} ($L_s$):
            Unlike the above, the end-to-end latency is determined by the \emph{critical path} of the dependency graph induced by $s_{\text{next}}$. Therefore, it cannot be computed additively but must be recomputed by Algorithm~\ref{alg:critical_path_latency}, implementing the recursive formulation defined in Equation~\ref{eq:latency_model}. This guarantees that $L_s$ always reflects the longest dependency chain in the current plan.
        \end{itemize}


        \begin{algorithm}[h]
            \caption{Compute Critical Path Latency}
            \label{alg:critical_path_latency}
            \SetAlgoLined
            \SetKwInOut{Parameter}{Parameters}
            \Parameter{Solution candidate $s$, processing order $\mathcal{O}^P_Q$}

            $L \gets \emptyset$ \tcp*[r]{Memo: projection $\rightarrow$ latency}
            $L_s \gets 0$\;

            \For{$p \in \mathcal{O}^P_Q$}{
              \If{$p \in \text{dom}(\mathcal{V}_s)$}{
                $v \gets \mathcal{V}_s(p)$ \tcp*[r]{Kraken Vertex}
                $\ell_{\text{pred}} \gets 0$\;
                \For{$d \in \delta(p)$}{
                  $\ell_{\text{pred}} \gets \max(\ell_{\text{pred}}, L[d])$ \tcp*[r]{Max predecessor}
                }
                $L[p] \gets \ell^t_v + \ell_{\text{pred}}$ \tcp*[r]{Eq.~\ref{eq:latency_model} with $\xi=0$}
                $L_s \gets \max(L_s, L[p])$\;
              }
            }

            \KwRet{$L_s$}
        \end{algorithm}

    \subsection{Multi-Objective State Scoring}\label{sec:multi_objective_state_scoring}

        After aggregation, each \emph{new} candidate state $s_{next}$ in the search pool has a final $C_s$ (see Equation~\ref{eq:state_cost_aggregation}) and $L_s$ (see Algorithm~\ref{alg:critical_path_latency}). To guide the search, we compare these states using a multi-objective function $F(s)$ that normalizes these heterogeneous metrics into a single, dimensionless score.

        Given a set of successor candidates $S_{next}$, we first normalize transmission cost relative to the set's range $[C_{min}, C_{max}]:$

        \begin{equation}\label{eq:cost_normalization}
            c_{norm}(s) =
            \begin{cases}
                \frac{C_s - C_{min}}{C_{max} - C_{min}} & \text{if } C_{max} > C_{min}\\

                0 &\text{otherwise}
          \end{cases}
        \end{equation}

        This maps the best candidate (lowest cost) to $0$ and the worst to $1$.

        We normalize the latency relative to the maximum allowed constraint $\Lambda_{max}$:

        \begin{equation}\label{eq:latency_normalization}
            \ell_{norm}(s) =
            \begin{cases}
                \frac{L_s}{\Lambda_{max}} & \text{if } \Lambda_{max} \in \mathbb{R}^+ \wedge \Lambda_{max} > 0\\

                0 &\text{otherwise}
          \end{cases}
        \end{equation}

        If no latency constraint exists ($\Lambda_{max} = \infty$), latency is excluded from optimization ($\ell_{norm}(s) = 0$).

        Finally, we combine these components using the problem's objective weights:

        \begin{equation}\label{eq:objective_function}
            F(s) = \alpha \cdot c_{norm}(s) + \beta \cdot \ell_{norm}(s)
        \end{equation}

        Search strategies (Section~\ref{sec:search_strategies}) use this function $F(s)$ to rank candidates, selecting those with the minimum score for expansion.

\section{Decoupled Search Strategies}\label{sec:search_strategies}

    Our framework's final component (C2) is a decoupled search layer that explores the solution space $\mathcal{S}$. By abstracting the domain logic behind the \texttt{expand} function and the $F(s)$ score (Equation~\ref{eq:objective_function}), we can apply generic search algorithms. We implement two strategies that trade solution quality for computational efficiency. We first introduce each strategie, i.e., Greedy Search in Section~\ref{} and Beam in Section~\ref{}, before we briefly, detail or explain how to enhance our search layer with further strategies in Section~\ref{}.

    \subsection{Greedy Search}

        Greedy search (Algorithm~\ref{alg:greedy}) implements a simple, efficient, best-first strategy. It maintains only a single current state $s$, initialized to $s_0$. In each step, it calls \texttt{expand}(s) and selects the top-scoring successor ($S'[0]$) as the new current state. It repeats this until a goal state is reached. This approach is computationally efficient but may converge to a locally optimal solution.

        \begin{algorithm}[h]
            \caption{Greedy Search}\label{alg:greedy}
            \SetAlgoLined
            \SetKwInOut{Parameter}{Parameters}
            \Parameter{Problem $\mathcal{P}$}

            $s \leftarrow s_0$ \tcp*[r]{Initialize with initial state}

            \While{$\neg \texttt{is\_goal}(s)$}{
              $S' \gets \texttt{expand}(s, \mathcal{P})$ \tcp*[r]{Get successors, sorted by score $F(s)$}
              \If{$S' = \emptyset$}{
                \textbf{error}: No valid solution found
              }
              $s \gets S'[0]$ \tcp*[r]{Select best successor}
            }
            \KwRet{$s$}
        \end{algorithm}

    \subsection{Beam-$k$ Search}

        Beam-$k$ search (Algorithm~\ref{alg:beam_k}) improves solution quality by maintaining $k$ parallel candidate solutions (the ``beam''). It initializes a beam $B$ with $s_0$. In each iteration, it expands \emph{all} states in $B$, collecting all their valid successors into a single candidate pool $C$. It then sorts $C$ globally by the objective score $F(s)$ (Equation~\ref{eq:objective_function}) and selects the top $k$ candidates to form the new beam $B$ for the next iteration. If any goal states are found, it returns the one with the best \emph{true} cumulative cost $C_s$.

        Setting $k=1$ reduces this to greedy search. Larger $k$ values explore more of the solution space, increasing the probability of finding a globally superior solution at the cost of $k$-times greater computational overhead.

        \begin{algorithm}[h]
            \caption{Beam-$k$ Search}\label{alg:beam_k}
            \SetAlgoLined
            \SetKwInOut{Parameter}{Parameters}
            \Parameter{Problem $\mathcal{P}$, beam width $k \in \mathbb{N}^+$}

            $B \leftarrow \{s_0\}$ \tcp*[r]{Initialize beam}

            \While{\textbf{true}}{
              $C \gets \emptyset$ \tcp*[r]{Candidate pool}
              $G \gets \emptyset$ \tcp*[r]{Goal states}

              \ForEach{$s \in B$}{
                \If{\texttt{is\_goal}($s$)}{
                  $G \gets G \cup \{s\}$\;
                  \textbf{continue}\;
                }
                $S' \gets \texttt{expand}(s, \mathcal{P})$ \tcp*[r]{Get locally sorted successors}
                $C \gets C \cup S'$ \tcp*[r]{Collect all successors}
              }

              \If{$G \neq \emptyset$}{
                \KwRet{$\arg\min_{s \in G} C_s$} \tcp*[r]{Best goal by actual cost $C_s$}
              }

              \If{$C = \emptyset$}{
                \If{$B \neq \emptyset$}{
                  \KwRet{$\arg\min_{s \in B} C_s$} \tcp*[r]{Best partial by actual cost $C_s$}
                }
                \textbf{error}: No valid solution found\;
              }

              $B \gets \texttt{select\_top\_k\_by\_score}(C, k)$ \tcp*[r]{Select global top-$k$ by score $F(s)$}
            }
        \end{algorithm}

    \subsection{Extensibility and Design Principles}\label{sec:extensibility}

        This decoupled architecture transforms the specialized CEP placement challenge into a generic combinatorial optimization problem. The domain logic is fully encapsulated within three operations: the \texttt{expand} state transition function (Algorithm~\ref{alg:expand}), the $F(s)$ objective function (Equation~\ref{eq:objective_function}), and the \texttt{is\_goal} predicate. This abstraction allows for the future integration of other search techniques, such as A* search (by defining an admissible heuristic) or branch-and-bound, without modifying the core cost evaluation framework or having to reason about domain specific knowledge like operator placement or push-pull communication.

\section{Correctness, Complexity and Limitations}\label{sec:correctness}

    We conclude this chapter by analyzing the theoretical properties of the Kraken framework. We address the correctness of our joing optmization model by justifying our integration of external components. We then analyze the computational complexity that necessitates our heuristic approach and, finally, discuss the limitations inherent in our design.

    \subsection{Correctness and Design Justification}

        Kraken ensures correctness by orchestrating two externally validated components: the INEv combination generator (\emph{split}) and the PrePP \emph{acquisition plan generator}. We do not modify their internal logic; instead, we integrate them as well-defined functions within our state-space search. Our central design decision involves using the INEv split function, which generates a combination $C_Q$ based on an all-push cost model, as the static input to our joint optimization. We selected this strategy for two primary reasons: ensuring plan validity and maintaining computational tractability.

        First, the all-push assumption guarantees a universally valid processing order. In a heterogeneous fog-cloud environment, we cannot know \emph{a priori} if an optimized push-pull plan is feasible at a given fog node, which may lack the resources for event buffering. By basing the combination on the all-push model, the \emph{split} algorithm provides a dependency graph that is guaranteed to be deployable. Our search algorithm then finds the optimal communication strategy for this valid dependency graph.

        \begin{figure}
            \centering
            \includegraphics[width=0.5
            \linewidth]{img/chapter4/inev_split.png}
            \caption{INEv \emph{split} function time share}
            \label{fig:inev_split_function}
        \end{figure}

        Second, integrating push-pull logic directly into the split function is \textbf{computationally infeasible}. The combination generation algorithm is already a significant performance bottleneck, consuming a majority of the pre-processing time in our experiments. Expanding this phase to consider all possible PrePP plans for every potential sub-projection would increase the computational cost exponentially, rendering the problem intractable for realistic workloads.
        \todo[inline]{include a simple figure showing the time for the longest and 10\% of longest experiments}

        Our framework validly substitutes \ac{INEv}'s original input cost model with the PrePP plan generator. The original \ac{INEv} placement algorithm treated input acquisition as a simple cost calculation. Our enhanced vertex (Definition~\ref{def:enhanced_inev_vertex}) replaces this with a call to the PrePP framework. Since PrePP finds the minimal-cost input plan for a given (projection, node) pair, it integrates cleanly into our state-space model, providing a far more accurate cost for the \emph{expand} function to evaluate.

    \subsection{Computational Complexity}

        The joint optimization problem solved by Kraken is NP-hard, as it integrates two computationally hard components: operator placement and communication strategy optimization.

        We inherit the combination generation (the split function) directly from INEv. This pre-processing step, which identifies all suitable projections and their dependencies, is itself exponential. As noted in the INEv paper, generating all combinations for a query $q$ has a time complexity of $O(|2^{\mathcal{E}(q)}| \cdot 2^{|2^{\mathcal{E}(q)}|})$ \cite{akili_inev_2023}. Kraken does not alter this step; we accept its output, a single valid combination $C_Q = (P, \delta)$, as the input to our search.

        Kraken's novelty lies in solving the placement and communication problem for this given combination. This corresponds to INEv's second construction step, which is also NP-hard\cite{akili_inev_2023}. We formalize the complexity of our specific task by analyzing the solution space $\mathcal{S}$ (Definition~\ref{def:solution_space}).

        \paragraph{Placement Search Space.}
            For a given combination with $k$ projections ($|P| = k$) and a network with $m$ potential fog and cloud nodes ($|N_f \cup N_c| = m$), our search algorithm must explore $O(m^k)$ possible placement configurations.

        \paragraph{Communication Complexity.}
            For each of these $O(m^k)$ configurations, our framework must determine the optimal communication strategy. This requires invoking the PrePP optimization. Finding the optimal PrePP plan requires solving the Pull Acquisition problem for its acquisition steps. This decision problem was proven to be NP-complete by a polynomial-time reduction from Vertex Cover\cite{purtzel_predicate-based_2022}. Therefore, finding the minimal-cost communication plan for a single (projection, node) pair is NP-hard.\\

            Kraken's joint optimization problem is thus a search across an $O(m^k)$ space, where each step involves solving an NP-hard subproblem (PrePP optimization). The combined solution space $\mathcal{S}$ (Definition~\ref{def:solution_space}) contains $O((m \cdot p)^k)$ possible complete INEv graphs, where $p$ represents the number of valid communication plans per node. This exponential complexity confirms that exhaustive search is infeasible and strongly justifies our use of heuristic search strategies like Greedy (Algorithm~\ref{alg:greedy}) and Beam-$k$ (Algorithm~\ref{alg:beam_k}).

    \subsection{Limitations and Future Work}

        Our framework, while providing a novel joint optimization, operates under several simplifying assumptions that define its four ... limitations. First, the most significant limitation is our reliance on the all-push-based INEv split function. This approach acts as a heuristic, pruning the search space before our joint optimization begins. It is possible that an optimal combination $C_Q^*$ exists only when considering push-pull costs, but our framework will not discover it. Second, we also limit the communication strategy search. Our framework (Algorithm~\ref{alg:expand}) only evaluates the single, minimal-cost PrePP plan ($\hat{p}_{PrePP}$) alongside the all-push baseline ($\hat{p}_{push}$). A more exhaustive search could request all valid (non-minimal) plans from PrePP, potentially finding a plan with slightly higher cost but significantly lower latency that our current model overlooks. A third limitation lies in our abstract cost metrics. Kraken optimizes for transmission cost (events per window) and transmission latency (hops), as defined in Chapter~\ref{cha:scientific_background}. These metrics do not directly map to real-world performance units, such as network bandwidth in bytes or processing time in milliseconds. Finally, our framework assumes a static network topology and workload, as defined in our problem statement (Chapter~\ref{cha:problem_statement}). It does not account for dynamic network conditions, node failures, or fluctuating event rates. Addressing these dynamic aspects remains a significant challenge for future work.
        All four limitations lie beyond the scope of this thesis but suggest promising directions for future work.